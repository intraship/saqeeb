{"cells":[{"cell_type":"markdown","id":"2e1b30ee-c39b-455a-bb2e-2578b2bbe176","metadata":{"id":"2e1b30ee-c39b-455a-bb2e-2578b2bbe176"},"source":["Assignment 4 Section 6.6 1,2,3,5,8,9"]},{"cell_type":"markdown","source":["Section 6.6"],"metadata":{"id":"v1mKR2gySZ_D"},"id":"v1mKR2gySZ_D"},{"cell_type":"markdown","source":["##E1:Best Subset, Forward & Backwards stepwise"],"metadata":{"id":"u3fGKUpOSf2J"},"id":"u3fGKUpOSf2J"},{"cell_type":"markdown","source":["A.\n","\n","Now, when the best subset selection is done, Best subset method will choose the model which has the **smallest training RSS** or least training error.\n","\n","Smallest RSS among the p-A models which augment the predictors under study in Af with one additional predictor p. Similar is the one for the backward stepwise selection where the model with the smallest RSS which contains all but one of the predictors."],"metadata":{"id":"jmPwPzghWxFj"},"id":"jmPwPzghWxFj"},{"cell_type":"markdown","source":["B. \n","\n","Best subset selection may have the **smallest test RSS** because it takes into account more models than the other methods under consideration. However depending on type of test/traiing set we have as well as method for validation, the best subset choosen may overfit the data\n","\n"],"metadata":{"id":"nE1pwmOfB3Rx"},"id":"nE1pwmOfB3Rx"},{"cell_type":"markdown","source":["C. \n","\n","* **True**, since the model under study with 4+1 predictors, is obtained by augmenting one more additional variable with the previous variables already present in the model\n","\n","* **True**, since this model with predictors is obtained by removing one varsable from the previous modes of +Ivanables\n","\n","* **False**, since no such direct relationship cannot be established between the backward and the forward selection model under consideration\n","\n","* **False**, due to the reason that there is no relationship between the backward and forward model\n","\n","* **False**, since the best model with +1 predictors, is obtained from the all possible models with A+1 predictors, and no model with predictors is taken into consideration\n","\n"],"metadata":{"id":"oqIFd6S1_SW9"},"id":"oqIFd6S1_SW9"},{"cell_type":"markdown","source":["##E2: "],"metadata":{"id":"kv9W-oBeVmMl"},"id":"kv9W-oBeVmMl"},{"cell_type":"markdown","source":["A.lasso vs least square\n","\n","*   **False**, lasso reduces no. of variables thus less flexible\n","*   **False**, lasso reduces no. of variables thus less flexible\n","*   **False**, lasso reduces variance & increases bias,reducing variance should compensate bias\n","*   **True**, Lasso is less flexible for eigenvalue>0, increasing predictor accuracy; increase in bias compensated by decrease in variance\n",">*   Lasso selcts B that minmises RSS + shrinkage penalty instead of RSS in least squares. Since the penalty is small for B,B2,...Bp (near zero), lasso shrink the estimate towards zero\n",">>*   when eignvalue>0, optimal lasso B will be close to zero than the least square B\n",">>*   For larger eigenvalue, skrinkage impact is higher relative to the RSS, skrinkage increases\n",">>*   skrinkage reduces the variance for a small increase in bias\n"],"metadata":{"id":"0POCs0XpCCCR"},"id":"0POCs0XpCCCR"},{"cell_type":"markdown","source":["B. Ridge vs Least Square\n","* False\n","* False\n","* False\n","* True, less flexible thus with increase in biass less than decrease in variance we improve prediction accuracy\n","> Ridge objection function is RSS + skrinkage penalty, its different from lasso since it wont skrink coefficent of less valued variables to zero\n"],"metadata":{"id":"6P0YTTNYFQxH"},"id":"6P0YTTNYFQxH"},{"cell_type":"markdown","source":["C. non-linear methods vs least square\n","* True, more flexible thus increase in variance that less than decrease in bias\n","> for y= f(x) + e\n","less assumptions for function F(), so its appromixated better with nonlinear relationships between predictors and response\n"],"metadata":{"id":"I4CIld8nFMPI"},"id":"I4CIld8nFMPI"},{"cell_type":"markdown","source":["##E3:"],"metadata":{"id":"9UYY-n2AVmdB"},"id":"9UYY-n2AVmdB"},{"cell_type":"markdown","source":["As we increase s from 0,\n","\n","A. training RSS\n","\n","steadily decrease (restricting B coefficentsto a lesser extent), model gets more flexible\n","\n","B. test RSS\n","\n","* Decrease initially, and then eventually start increasing in a U-shape, due to the model becomes more and more flexible, and then due to extra parameters, it does overestimation.\n","\n","\n","C. variance\n","\n","* Steadily increase, since a more flexible model induces to a higher and larger variance\n","\n","\n","D. squared bias\n","\n","* Steadily decrease, since more is the variance, the bias of the model will decrease, since the model becomes more flexible.\n","\n","\n","E. irreducible error\n","\n","* Remains constant, since the definition of enor is in that way for any model of any parameters"],"metadata":{"id":"CPvpAvkEurUz"},"id":"CPvpAvkEurUz"},{"cell_type":"markdown","source":["##E5: *See notes*\n"],"metadata":{"id":"A1gqVbJ4Vmp9"},"id":"A1gqVbJ4Vmp9"},{"cell_type":"markdown","source":["#E8:"],"metadata":{"id":"VcGA6dmFVqIs"},"id":"VcGA6dmFVqIs"},{"cell_type":"markdown","source":["##A. use rnorm function"],"metadata":{"id":"7-d2FuNWmyC-"},"id":"7-d2FuNWmyC-"},{"cell_type":"code","source":["set.seed(1)\n","\n","x   <- rnorm(100)\n","\n","err <- rnorm(100)\n"],"metadata":{"id":"ghJ_uDMPmiTh"},"id":"ghJ_uDMPmiTh","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##B.\n","\n","Now the model with assumed coefficient values is obtained with the help of the below given"],"metadata":{"id":"3gHzJGOxvML4"},"id":"3gHzJGOxvML4"},{"cell_type":"code","source":["b0 <- 4\n","\n","b1 <- 3\n","\n","b2 <- -1\n","\n","b3 <- 0.75\n","\n","y <- b0 +b1 * x + b2 * x^2+ b3 * x^3 + err\n"],"metadata":{"id":"VRH0kUK6m9Ua"},"id":"VRH0kUK6m9Ua","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##C. best subset selection"],"metadata":{"id":"xRn-TaGOnB27"},"id":"xRn-TaGOnB27"},{"cell_type":"code","source":["library(leaps)\n","\n","data.full <- data.frame(y = y, x = x)\n","\n","regfit.full <- regsubsets(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full, nvmax = 10)\n","\n","reg.summary <- summary(regfit.full)\n","\n","par(nfrow = c(2,2))\n","\n","plot(reg.summary$cp, xlab = \"Number of variables\", ylab=\"C_p\", type=\"l\") \n","\n","points(which.min(reg.summary$cp),\n","reg.summary$cp[which.min(reg.summary$cp)], col =  \"red\", cex = 2, pch = 20)\n","\n","plot(reg.summary$bic, xlab = \"Number of variables\", ylab = \"BIC\", type=\"l\") \n","\n","points(which.min(reg.summary$bic),\n","reg.summary$bic[which.min(reg.summary$bic)], col = \"red\", cex = 2 , pch = 20)\n","\n","plot(reg.summary$adjr2, xlab = \"Number of variables\", ylab = \"Adjusted R^2\", type=\"l\")\n","\n","points(which.max(reg.summary $adjr2), reg.summary$adjr2[which.max(reg.summary$adjr2)], col = \"red\", cex = 2, pch = 20)"],"metadata":{"id":"n0UFG_Z7nJL8"},"id":"n0UFG_Z7nJL8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coef(regfit.full, which.max(reg.summary$adjr2))"],"metadata":{"id":"dMGluwcsnYZ8"},"id":"dMGluwcsnYZ8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#output\n","(Intercept)           x      I(x^2)      I(x^3)      I(x^5) \n"," 4.07200775  3.38745596 -1.15424359  0.30797426  0.08072292 "],"metadata":{"id":"7O8dVvPXclVr"},"id":"7O8dVvPXclVr","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##D.i forward Stepwise selection"],"metadata":{"id":"cdc-Y_HqpaOq"},"id":"cdc-Y_HqpaOq"},{"cell_type":"code","source":["regfit.fwd <- regsubsets(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) +\n","I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full, nvmax = 10, method =\n","\"forward\")\n","reg.summary.fwd <- summary(regfit.fwd)\n","par(mfrow = c(2, 2))\n","plot(reg.summary.fwd$cp, xlab = \"No. of variables\", ylab = \"Mallow's C_p\",\n","type = \"l\")\n","points(which.min(reg.summary.fwd$cp),\n","reg.summary.fwd$cp[which.min(reg.summary.fwd$cp)], col = \"purple\", cex = 2 , pch = 20)\n","plot(reg.summary.fwd$bic, xlab = \"No. of variables\", ylab = \"BIC\", type =\n","\"l\")\n","points(which.min(reg.summary.fwd$bic),\n","reg.summary.fwd$bic[which.min(reg.summary.fwd$bic)], col = \"purple\", cex = 2 , pch = 20)\n","plot(reg.summary.fwd$adjr2, xlab = \"No. of variables\", ylab = \"Adjusted R^2\",\n","type = \"l\")\n","points(which.max(reg.summary.fwd$adjr2),\n","reg.summary.fwd$adjr2[which.max(reg.summary.fwd$adjr2)], col = \"purple\", cex = 2 , pch = 20)\n","mtext(\"Plots of C_p, BIC and adjusted R^2 for forward stepwise selection\",\n","side = 3, line = -2, outer = TRUE)\n"],"metadata":{"id":"rpGVZTa-nl1Q"},"id":"rpGVZTa-nl1Q","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coef(regfit.fwd, which.max(reg.summary.fwd$adjr2))"],"metadata":{"id":"028yJonfp_iu"},"id":"028yJonfp_iu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#output\n","(Intercept)           x      I(x^2)      I(x^3)      I(x^5) \n"," 4.07200775  3.38745596 -1.15424359  0.30797426  0.08072292 "],"metadata":{"id":"TZzif__9dINT"},"id":"TZzif__9dINT","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##D.ii backward stepwise selection"],"metadata":{"id":"Csycx1SKpwdO"},"id":"Csycx1SKpwdO"},{"cell_type":"code","source":["regfit.bwd <- regsubsets(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) +\n","I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full, nvmax = 10, method =\n","\"backward\")\n","reg.summary.bwd <- summary(regfit.bwd)\n","par(mfrow = c(2, 2))\n","plot(reg.summary.bwd$cp, xlab = \"No. of variables\", ylab = \"C_p\",\n","type = \"l\")\n","points(which.min(reg.summary.bwd$cp),\n","reg.summary.bwd$cp[which.min(reg.summary.bwd$cp)], col = \"black\", cex = 4,\n","pch = 20)\n","plot(reg.summary.bwd$bic, xlab = \"No. of variables\", ylab = \"BIC\", type =\n","\"l\")\n","points(which.min(reg.summary.bwd$bic),\n","reg.summary.bwd$bic[which.min(reg.summary.bwd$bic)], col = \"black\", cex = 4,\n","pch = 20)\n","plot(reg.summary.bwd$adjr2, xlab = \"No. of variables\", ylab = \"Adjusted R^2\",\n","type = \"l\")\n","points(which.max(reg.summary.bwd$adjr2),\n","reg.summary.bwd$adjr2[which.max(reg.summary.bwd$adjr2)], col = \"black\", cex =\n","4, pch = 20)\n","mtext(\"Plots of C_p, BIC and adjusted R^2 for backward stepwise selection\",\n","side = 3, line = -2, outer = TRUE)\n"],"metadata":{"id":"wBt9_5NMnpcZ"},"id":"wBt9_5NMnpcZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coef(regfit.bwd, which.max(reg.summary.bwd$adjr2))\n"],"metadata":{"id":"P4f4_mQ_qEKm"},"id":"P4f4_mQ_qEKm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#output\n","(Intercept)           x      I(x^2)      I(x^5)      I(x^7) \n"," 4.06541226  3.56028595 -1.14393799  0.20400609 -0.01343328 "],"metadata":{"id":"pqLOPaVSdXr1"},"id":"pqLOPaVSdXr1","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## E."],"metadata":{"id":"6OvELPd13gJt"},"id":"6OvELPd13gJt"},{"cell_type":"code","source":["fit.lasso <- glmnet(xmat, y, alpha = 1)\n","predict(fit.lasso, s = bestlam, type = \"coefficients\")[1:11, ]"],"metadata":{"id":"ncs5jvOfn_WX"},"id":"ncs5jvOfn_WX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["xmat <- model.matrix(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) +\n","I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full)[, -1]\n","cv.lasso <- cv.glmnet(xmat, y, alpha = 1)\n","plot(cv.lasso)"],"metadata":{"id":"ofJgTEAToNZR"},"id":"ofJgTEAToNZR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["bestlam <- cv.lasso$lambda.min\n","bestlam"],"metadata":{"id":"HNr4usSGqjUY"},"id":"HNr4usSGqjUY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit.lasso <- glmnet(xmat, y, alpha = 1)\n","predict(fit.lasso, s = bestlam, type = \"coefficients\")[1:11, ]"],"metadata":{"id":"rv-YfKsHoRWU"},"id":"rv-YfKsHoRWU","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## F. Perform best subset selection & lasso"],"metadata":{"id":"zbMpc2Kwqx2S"},"id":"zbMpc2Kwqx2S"},{"cell_type":"code","source":["b7 <- 7\n","y <- b0 + b7 * x^7 + err\n","data.full <- data.frame(y = y, x = x)\n","regfit.full <- regsubsets(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6)\n","+ I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full, nvmax = 10)\n","\n","\n","reg.summary <- summary(regfit.full)\n","par(mfrow = c(2, 2))\n","plot(reg.summary$cp, xlab = \"Number of variables\", ylab = \"C_p\", type = \"l\")\n","points(which.min(reg.summary$cp), reg.summary$cp[which.min(reg.summary$cp)],\n","col = \"red\", cex = 2, pch = 20)\n","plot(reg.summary$bic, xlab = \"Number of variables\", ylab = \"BIC\", type = \"l\")\n","points(which.min(reg.summary$bic),\n","reg.summary$bic[which.min(reg.summary$bic)], col = \"red\", cex = 2, pch = 20)\n","plot(reg.summary$adjr2, xlab = \"Number of variables\", ylab = \"Adjusted R^2\",\n","type = \"l\")\n","points(which.max(reg.summary$adjr2),\n","reg.summary$adjr2[which.max(reg.summary$adjr2)], col = \"red\", cex = 2, pch =\n","20)"],"metadata":{"id":"x5bXECjToEPI"},"id":"x5bXECjToEPI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coef(regfit.full, 1)"],"metadata":{"id":"IXZkPY0GoHHB"},"id":"IXZkPY0GoHHB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coef(regfit.full, 2)"],"metadata":{"id":"Wu2oOjvBoYgq"},"id":"Wu2oOjvBoYgq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["coef(regfit.full, 4)"],"metadata":{"id":"USc7o3leoYYm"},"id":"USc7o3leoYYm","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##lasso"],"metadata":{"id":"KiXT0rO4rYZJ"},"id":"KiXT0rO4rYZJ"},{"cell_type":"code","source":["xmat <- model.matrix(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) +\n","I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full)[, -1]\n","cv.lasso <- cv.glmnet(xmat, y, alpha = 1)\n","bestlam <- cv.lasso$lambda.min\n","bestlam\n"],"metadata":{"id":"dWItLGrCrXhj"},"id":"dWItLGrCrXhj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit.lasso <- glmnet(xmat, y, alpha = 1)\n","predict(fit.lasso, s = bestlam, type = \"coefficients\")[1:11, ]"],"metadata":{"id":"hhOXYBhGrcAn"},"id":"hhOXYBhGrcAn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##E9:"],"metadata":{"id":"bmx0l0JySksc"},"id":"bmx0l0JySksc"},{"cell_type":"code","source":["library(ISLR)\n","data(College)\n","set.seed(11)\n","train = sample(1:dim(College)[1], dim(College)[1] / 2)\n","test <- -train\n","College.train <- College[train, ]\n","College.test <- College[test, ]"],"metadata":{"id":"jqZ3y3CMe1An"},"id":"jqZ3y3CMe1An","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["B. The least square for the model fitted is obtained by:\n","\n"],"metadata":{"id":"6eBMhEvZSQHu"},"id":"6eBMhEvZSQHu"},{"cell_type":"code","source":["fit.lm <- lm(Apps ~ ., data = College.train)\n","\n","pred.lm <- predict(fit.lm, College.test)\n","\n","mean((pred.lm - College.test$Apps)^2)\n","\n","# 1026096\n","## Test-MSE is 1.026096 * 10^6"],"metadata":{"id":"f12tx4z3fSch"},"id":"f12tx4z3fSch","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["C. *Now obtaining the test error after fitting a ridge regression model to the given data set is obtained*"],"metadata":{"id":"x4hamwe4TVVb"},"id":"x4hamwe4TVVb"},{"cell_type":"code","source":["train.mat <- model.matrix(Apps ~ ., data = College.train)\n","\n","test.mat <- model.matrix(Apps ~ ., data = College.test)\n"," \n","grid <- 10 ^ seq(4, -2, length = 100)\n","\n","fit.ridge <- glmnet(train.mat, College.train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)\n","\n","cv.ridge  <- cv.glmnet(train.mat, College.train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)\n","\n","bestlam.ridge <- cv.ridge$lambda.min\n","\n","bestlam.ridge\n","\n","# 0.01"],"metadata":{"id":"eort1QMnfZR-"},"id":"eort1QMnfZR-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred.ridge <- predict(fit.ridge, s = bestlam.ridge, newx = test.mat)\n","\n","mean((pred.ridge - College.test$Apps)^2)\n","\n","# 1026069 or 1.026069 * 10^6\n","# the test MSE for ridge is insignificantly less or about the same as for least squares"],"metadata":{"id":"QRoQ1bOxgYB3"},"id":"QRoQ1bOxgYB3","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["D. fit lasso model on training set, report test error\n","\n"],"metadata":{"id":"GWS7NcJZwhte"},"id":"GWS7NcJZwhte"},{"cell_type":"code","source":["fit.lasso <- glmnet(train.mat, College.train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)\n","\n","cv.lasso <- cv.glmnet(train.mat, College.train$Apps, alpha = 0, lambda = grid, thresh = 1e-12)\n","\n","bestlam.lasso <- cv.lasso$lambda.min\n","\n","bestlam.lasso\n","\n","# 0.01\n","\n","pred.lasso <- predict(fit.lasso, s = bestlam.lasso, newx = test.mat)\n","\n","mean((pred.lasso - College.test$Apps)^2)\n","\n","# 1026069\n","# The test MSE is the same as for ridge regression and least squares\n","\n","predict(fit.lasso, s = bestlam.lasso, type = \"coefficients\")\n","\n","#output\n","19 x 1 sparse Matrix of class \"dgCMatrix\"\n","                       s1\n","(Intercept)   37.94611433\n","(Intercept)    .         \n","PrivateYes  -551.14579225\n","Accept         1.74982651\n","Enroll        -1.36037165\n","Top10perc     65.56220745\n","Top25perc    -22.53142677\n","F.Undergrad    0.10187088\n","P.Undergrad    0.01788531\n","Outstate      -0.08707414\n","Room.Board     0.15386306\n","Books         -0.12236837\n","Personal       0.16195345\n","PhD          -14.29775250\n","Terminal      -1.03116622\n","S.F.Ratio      4.48308678\n","perc.alumni   -0.45522049\n","Expend         0.05618641\n","Grad.Rate      9.07461299"],"metadata":{"id":"Al89QQXJiAEi"},"id":"Al89QQXJiAEi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["library(pls)\n","fit.pcr <- pcr(Apps ~ ., data = College.train, scale = TRUE, validation =\n","\"CV\")\n","validationplot(fit.pcr, val.type = \"MSEP\")\n","\n","pred.pcr <- predict(fit.pcr, College.test, ncomp = 10)\n","mean((pred.pcr - College.test$Apps)^2)\n","# 1867486\n","# Test MSE is higher for PCR than others"],"metadata":{"id":"EB5Yj1kWjf7M"},"id":"EB5Yj1kWjf7M","execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit.pls <- plsr(Apps ~ ., data = College.train, scale = TRUE, validation =\n","\"CV\")\n","validationplot(fit.pls, val.type = \"MSEP\")\n","\n","pred.pls <- predict(fit.pls, College.test, ncomp = 10)\n","mean((pred.pls - College.test$Apps)^2)\n","\n","# 1031287\n","# The test MSE is lower than for least squares & others"],"metadata":{"id":"rA3w1QDljsXV"},"id":"rA3w1QDljsXV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.avg <- mean(College.test$Apps)\n","lm.r2 <- 1 - mean((pred.lm - College.test$Apps)^2) / mean((test.avg -\n","College.test$Apps)^2)\n","cat('\\nlm.r2: ',lm.r2)\n","# lm.r2: 0.9104228"],"metadata":{"id":"iF0IBP0Wj_sF"},"id":"iF0IBP0Wj_sF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["ridge.r2 <- 1 - mean((pred.ridge - College.test$Apps)^2) / mean((test.avg - College.test$Apps)^2)\n","\n","cat('\\nridge.r2: ', ridge.r2)\n","# ridge.r2:  0.9104252\n","\n","lasso.r2 <- 1 - mean((pred.lasso - College.test$Apps)^2) / mean((test.avg - College.test$Apps)^2)\n","\n","cat('\\nlasso.r2: ', lasso.r2)\n","# lasso.r2:  0.9104252\n","\n","pcr.r2 <- 1 - mean((pred.pcr - College.test$Apps)^2) / mean((test.avg - College.test$Apps)^2)\n","\n","cat('\\npcr.r2: ', pcr.r2)\n","# pcr.r2:  0.8369703\n","\n","pls.r2 <- 1 - mean((pred.pls - College.test$Apps)^2) / mean((test.avg - College.test$Apps)^2)\n","\n","cat('\\npls.r2: ', pls.r2)\n","# pls.r2:  0.9099696\n","\n","## Nearly every model has high accuracy over 90% except pcr with ~ 83.70%"],"metadata":{"id":"_mI4Gx2NkiMJ"},"id":"_mI4Gx2NkiMJ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"Muhammad-Saqeeb-hw4.ipynb","provenance":[],"collapsed_sections":["u3fGKUpOSf2J","kv9W-oBeVmMl","9UYY-n2AVmdB","bmx0l0JySksc"]}},"nbformat":4,"nbformat_minor":5}